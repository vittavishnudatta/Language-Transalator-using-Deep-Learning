{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e65fa4fd",
   "metadata": {
    "id": "e65fa4fd"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "from numpy import array\n",
    "import string\n",
    "import re\n",
    "from numpy import array, argmax, random, take\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding, RepeatVector\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "from pickle import load\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers import TimeDistributed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "m034xz0yesRZ",
   "metadata": {
    "id": "m034xz0yesRZ"
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "import numpy as np\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Model\n",
    "from keras.layers import GRU, Input, Dense, TimeDistributed, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import sparse_categorical_crossentropy, huber_loss, categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ieUwiVWajC7w",
   "metadata": {
    "id": "ieUwiVWajC7w"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "def load_data(path):\n",
    "    \"\"\"\n",
    "    Load Dataset from File\n",
    "    \"\"\"\n",
    "    input_file = os.path.join(path)\n",
    "    with open(input_file, \"r\",encoding=\"utf8\") as f:\n",
    "        data = f.read().splitlines()\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "817a3d30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "817a3d30",
    "outputId": "a91fdd76-bb5b-4bc0-b105-6f0f3236b48d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Loaded\n"
     ]
    }
   ],
   "source": [
    "english_sentences = load_data('all_eng.txt')\n",
    "other_sentences = load_data('all_others.txt')\n",
    "print('Dataset Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "QUJWoZerkVM-",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QUJWoZerkVM-",
    "outputId": "2d84801b-4446-4d82-ac86-d53b75b45272"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "064ef733",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "064ef733",
    "outputId": "1582fe4c-4cfb-49c4-a06c-8726289ea579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "small_vocab_en Line 1:  joker\n",
      "small_vocab_or Line 1:  கோமாளித்தனம்\n",
      "small_vocab_en Line 2:  Related Pages\n",
      "small_vocab_or Line 2:  தொடர்பான பக்கங்கள்\n"
     ]
    }
   ],
   "source": [
    "for sample_i in range(2):\n",
    "    print('small_vocab_en Line {}:  {}'.format(sample_i + 1, english_sentences[sample_i]))\n",
    "    print('small_vocab_or Line {}:  {}'.format(sample_i + 1, other_sentences[sample_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "807fe3c4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "807fe3c4",
    "outputId": "59032ae0-2e48-4d2f-cbfa-2f7d372ed7f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48310 English words.\n",
      "14307 unique English words.\n",
      "10 Most common words in the English dataset:\n",
      "\"the\" \"of\" \"in\" \"and\" \"is\" \"to\" \"was\" \"are\" \"a\" \"for\"\n",
      "\n",
      "43636 other words.\n",
      "20918 unique other words.\n",
      "10 Most common words in the others dataset:\n",
      "\"के\" \"में\" \"-\" \"का\" \"की\" \"से\" \"है।\" \"और\" \"दिल्ली\" \"को\"\n"
     ]
    }
   ],
   "source": [
    "english_words_counter = collections.Counter([word for sentence in english_sentences for word in sentence.split()])\n",
    "other_words_counter = collections.Counter([word for sentence in other_sentences for word in sentence.split()])\n",
    "print('{} English words.'.format(len([word for sentence in english_sentences for word in sentence.split()])))\n",
    "print('{} unique English words.'.format(len(english_words_counter)))\n",
    "print('10 Most common words in the English dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*english_words_counter.most_common(10)))[0]) + '\"')\n",
    "print()\n",
    "print('{} other words.'.format(len([word for sentence in other_sentences for word in sentence.split()])))\n",
    "print('{} unique other words.'.format(len(other_words_counter)))\n",
    "print('10 Most common words in the others dataset:')\n",
    "print('\"' + '\" \"'.join(list(zip(*other_words_counter.most_common(10)))[0]) + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81799209",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "81799209",
    "outputId": "11a1cbaf-1f61-4e39-8f12-38559cd03c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 1, 'quick': 2, 'a': 3, 'brown': 4, 'fox': 5, 'jumps': 6, 'over': 7, 'lazy': 8, 'dog': 9, 'by': 10, 'jove': 11, 'my': 12, 'study': 13, 'of': 14, 'lexicography': 15, 'won': 16, 'prize': 17, 'this': 18, 'is': 19, 'short': 20, 'sentence': 21}\n",
      "\n",
      "Sequence 1 in x\n",
      "  Input:  The quick brown fox jumps over the lazy dog .\n",
      "  Output: [1, 2, 4, 5, 6, 7, 1, 8, 9]\n",
      "Sequence 2 in x\n",
      "  Input:  By Jove , my quick study of lexicography won a prize .\n",
      "  Output: [10, 11, 12, 2, 13, 14, 15, 16, 3, 17]\n",
      "Sequence 3 in x\n",
      "  Input:  This is a short sentence .\n",
      "  Output: [18, 19, 3, 20, 21]\n"
     ]
    }
   ],
   "source": [
    "def tokenize(x):\n",
    "    x_tk = Tokenizer(char_level = False)\n",
    "    x_tk.fit_on_texts(x)\n",
    "    return x_tk.texts_to_sequences(x), x_tk\n",
    "text_sentences = [\n",
    "    'The quick brown fox jumps over the lazy dog .',\n",
    "    'By Jove , my quick study of lexicography won a prize .',\n",
    "    'This is a short sentence .']\n",
    "text_tokenized, text_tokenizer = tokenize(text_sentences)\n",
    "print(text_tokenizer.word_index)\n",
    "print()\n",
    "for sample_i, (sent, token_sent) in enumerate(zip(text_sentences, text_tokenized)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(sent))\n",
    "    print('  Output: {}'.format(token_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c0a61a93",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0a61a93",
    "outputId": "28c40aa1-9ea9-4e01-910b-52afed4253fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence 1 in x\n",
      "  Input:  [1 2 4 5 6 7 1 8 9]\n",
      "  Output: [1 2 4 5 6 7 1 8 9 0]\n",
      "Sequence 2 in x\n",
      "  Input:  [10 11 12  2 13 14 15 16  3 17]\n",
      "  Output: [10 11 12  2 13 14 15 16  3 17]\n",
      "Sequence 3 in x\n",
      "  Input:  [18 19  3 20 21]\n",
      "  Output: [18 19  3 20 21  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "def pad(x, length=None):\n",
    "    if length is None:\n",
    "        length = max([len(sentence) for sentence in x])\n",
    "    return pad_sequences(x, maxlen = length, padding = 'post')\n",
    "# Pad Tokenized output\n",
    "test_pad = pad(text_tokenized)\n",
    "for sample_i, (token_sent, pad_sent) in enumerate(zip(text_tokenized, test_pad)):\n",
    "    print('Sequence {} in x'.format(sample_i + 1))\n",
    "    print('  Input:  {}'.format(np.array(token_sent)))\n",
    "    print('  Output: {}'.format(pad_sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c033886b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c033886b",
    "outputId": "eee95f2a-41eb-48b6-d9bf-fb8d0a5a798e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Preprocessed\n",
      "Max English sentence length: 130\n",
      "Max other sentence length: 208\n",
      "English vocabulary size: 9882\n",
      "other vocabulary size: 19874\n"
     ]
    }
   ],
   "source": [
    "def preprocess(x, y):\n",
    "    preprocess_x, x_tk = tokenize(x)\n",
    "    preprocess_y, y_tk = tokenize(y)\n",
    "    preprocess_x = pad(preprocess_x)\n",
    "    preprocess_y = pad(preprocess_y)\n",
    "# Keras's sparse_categorical_crossentropy function requires the labels to be in 3 dimensions\n",
    "    preprocess_y = preprocess_y.reshape(*preprocess_y.shape, 1)\n",
    "    return preprocess_x, preprocess_y, x_tk, y_tk\n",
    "preproc_english_sentences, preproc_other_sentences, english_tokenizer, other_tokenizer =\\\n",
    "    preprocess(english_sentences, other_sentences)\n",
    "    \n",
    "max_english_sequence_length = preproc_english_sentences.shape[1]\n",
    "max_other_sequence_length = preproc_other_sentences.shape[1]\n",
    "english_vocab_size = len(english_tokenizer.word_index)\n",
    "other_vocab_size = len(other_tokenizer.word_index)\n",
    "print('Data Preprocessed')\n",
    "print(\"Max English sentence length:\", max_english_sequence_length)\n",
    "print(\"Max other sentence length:\", max_other_sequence_length)\n",
    "print(\"English vocabulary size:\", english_vocab_size)\n",
    "print(\"other vocabulary size:\", other_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b9271a53",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b9271a53",
    "outputId": "5c0957b0-8748-42f1-a7e6-d61a44858a91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`logits_to_text` function loaded.\n"
     ]
    }
   ],
   "source": [
    "def logits_to_text(logits, tokenizer):\n",
    "    index_to_words = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    index_to_words[0] = '<PAD>'\n",
    "    return ' '.join([index_to_words[prediction] for prediction in np.argmax(logits, 1)])\n",
    "print('`logits_to_text` function loaded.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f3fa1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "mixed_cross_entropy_loss = nn.BCEWithLogitsLoss(pos_weight=torch.tensor([4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5658710",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "f5658710",
    "outputId": "2143658f-ed86-49f6-d06f-a0d5b6bcb55f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "31/31 [==============================] - 125s 4s/step - loss: 183.1775 - accuracy: 0.7876 - val_loss: 378.1929 - val_accuracy: 0.7838\n",
      "Epoch 2/10\n",
      "31/31 [==============================] - 169s 6s/step - loss: 183.1775 - accuracy: 0.7870 - val_loss: 378.1929 - val_accuracy: 0.7825\n",
      "Epoch 3/10\n",
      "31/31 [==============================] - 135s 4s/step - loss: 183.1775 - accuracy: 0.7835 - val_loss: 378.1929 - val_accuracy: 0.7735\n",
      "Epoch 4/10\n",
      "31/31 [==============================] - 122s 4s/step - loss: 183.1775 - accuracy: 0.2824 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "31/31 [==============================] - 119s 4s/step - loss: 183.1774 - accuracy: 3.1268e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "31/31 [==============================] - 130s 4s/step - loss: 183.1774 - accuracy: 2.1262e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "31/31 [==============================] - 117s 4s/step - loss: 183.1775 - accuracy: 2.1262e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "31/31 [==============================] - 116s 4s/step - loss: 183.1774 - accuracy: 2.1262e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "31/31 [==============================] - 121s 4s/step - loss: 183.1774 - accuracy: 2.1262e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "31/31 [==============================] - 118s 4s/step - loss: 183.1774 - accuracy: 2.1262e-05 - val_loss: 378.1929 - val_accuracy: 0.0000e+00\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "मुख्य అతని மேல் மேல் மேல் மேல் மேல் மேல் அவர் அவர் వైపున వైపున எனது எனது எனது எனது எனது எனது எனது சிறிய சிறிய சிறிய திருப்பம் திருப்பம் திருப்பம் திருப்பம் திருப்பம் பொதுவாக பொதுவாக பொதுவாக நடத்திய நடத்திய நடிகர் முடிவு संख्या संख्या संख्या నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి నుంచి\n"
     ]
    }
   ],
   "source": [
    "def simple_model(input_shape, output_sequence_length, english_vocab_size, other_vocab_size):\n",
    "    learning_rate = 1e-3\n",
    "    input_seq = Input(input_shape[1:])\n",
    "    rnn = GRU(64, return_sequences = True)(input_seq)\n",
    "    logits = TimeDistributed(Dense(4720))(rnn)\n",
    "    model = Model(input_seq, Activation('softmax')(logits))\n",
    "    model.compile(loss = huber_loss, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "tmp_x = pad(preproc_english_sentences, max_other_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_other_sentences.shape[-2], 1))\n",
    "tmp_x=np.delete(tmp_x,1,0)\n",
    "# Train the neural network\n",
    "simple_rnn_model = simple_model(\n",
    "    tmp_x.shape,\n",
    "    max_other_sequence_length,\n",
    "    english_vocab_size,\n",
    "    other_vocab_size)\n",
    "simple_rnn_model.fit(tmp_x, preproc_other_sentences, batch_size=128, epochs=10, validation_split=0.2)\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(simple_rnn_model.predict(tmp_x[:1])[0], other_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "60c1f12a",
   "metadata": {
    "id": "60c1f12a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'huber/Sub' defined at (most recent call last):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Shreyas\\AppData\\Local\\Temp\\ipykernel_10940\\3724361515.py\", line 26, in <cell line: 26>\n      embeded_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1879, in huber\n      error = tf.subtract(y_pred, y_true)\nNode: 'huber/Sub'\nOOM when allocating tensor with shape[1024,208,19874] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node huber/Sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_33789]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m tmp_x \u001b[38;5;241m=\u001b[39m tmp_x\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, preproc_other_sentences\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]))\n\u001b[0;32m     21\u001b[0m embeded_model \u001b[38;5;241m=\u001b[39m embed_model(\n\u001b[0;32m     22\u001b[0m     tmp_x\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     23\u001b[0m     max_other_sequence_length,\n\u001b[0;32m     24\u001b[0m     english_vocab_size,\n\u001b[0;32m     25\u001b[0m     other_vocab_size)\n\u001b[1;32m---> 26\u001b[0m \u001b[43membeded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreproc_other_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits_to_text(embeded_model\u001b[38;5;241m.\u001b[39mpredict(tmp_x[:\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m], other_tokenizer))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'huber/Sub' defined at (most recent call last):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Shreyas\\AppData\\Local\\Temp\\ipykernel_10940\\3724361515.py\", line 26, in <cell line: 26>\n      embeded_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1879, in huber\n      error = tf.subtract(y_pred, y_true)\nNode: 'huber/Sub'\nOOM when allocating tensor with shape[1024,208,19874] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node huber/Sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_33789]"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "def embed_model(input_shape, output_sequence_length, english_vocab_size, other_vocab_size):\n",
    "    learning_rate = 1e-3\n",
    "    rnn = GRU(64, return_sequences=True, activation=\"tanh\")\n",
    "    \n",
    "    embedding = Embedding(other_vocab_size, 64, input_length=input_shape[1]) \n",
    "    logits = TimeDistributed(Dense(other_vocab_size, activation=\"softmax\"))\n",
    "    \n",
    "    model = Sequential()\n",
    "    #em can only be used in first layer --> Keras Documentation\n",
    "    model.add(embedding)\n",
    "    model.add(rnn)\n",
    "    model.add(logits)\n",
    "    model.compile(loss=huber_loss,\n",
    "                  optimizer=Adam(learning_rate),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "tmp_x = pad(preproc_english_sentences, max_other_sequence_length)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_other_sentences.shape[-2]))\n",
    "embeded_model = embed_model(\n",
    "    tmp_x.shape,\n",
    "    max_other_sequence_length,\n",
    "    english_vocab_size,\n",
    "    other_vocab_size)\n",
    "embeded_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=10, validation_split=0.2)\n",
    "print(logits_to_text(embeded_model.predict(tmp_x[:1])[0], other_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4a414e14",
   "metadata": {
    "id": "4a414e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "Graph execution error:\n\nDetected at node 'huber/Sub' defined at (most recent call last):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Shreyas\\AppData\\Local\\Temp\\ipykernel_10940\\4290154479.py\", line 21, in <cell line: 21>\n      bidi_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1879, in huber\n      error = tf.subtract(y_pred, y_true)\nNode: 'huber/Sub'\nOOM when allocating tensor with shape[1024,208,19875] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node huber/Sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_30571]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m tmp_x\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdelete(tmp_x,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m bidi_model \u001b[38;5;241m=\u001b[39m bd_model(\n\u001b[0;32m     17\u001b[0m     tmp_x\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m     18\u001b[0m     preproc_other_sentences\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mlen\u001b[39m(english_tokenizer\u001b[38;5;241m.\u001b[39mword_index)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;28mlen\u001b[39m(other_tokenizer\u001b[38;5;241m.\u001b[39mword_index)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m \u001b[43mbidi_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreproc_other_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Print prediction(s)\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(logits_to_text(bidi_model\u001b[38;5;241m.\u001b[39mpredict(tmp_x[:\u001b[38;5;241m1\u001b[39m])[\u001b[38;5;241m0\u001b[39m], other_tokenizer))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'huber/Sub' defined at (most recent call last):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 194, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 846, in launch_instance\n      app.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 712, in start\n      self.io_loop.start()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 199, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 570, in run_forever\n      self._run_once()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\base_events.py\", line 1859, in _run_once\n      handle._run()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\asyncio\\events.py\", line 81, in _run\n      self._context.run(self._callback, *self._args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 510, in dispatch_queue\n      await self.process_one()\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 499, in process_one\n      await dispatch(*args)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 406, in dispatch_shell\n      await result\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 730, in execute_request\n      reply_content = await reply_content\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 383, in do_execute\n      res = shell.run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 528, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2881, in run_cell\n      result = self._run_cell(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2936, in _run_cell\n      return runner(coro)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3135, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3338, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3398, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\Shreyas\\AppData\\Local\\Temp\\ipykernel_10940\\4290154479.py\", line 21, in <cell line: 21>\n      bidi_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1564, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1160, in train_function\n      return step_function(self, iterator)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1146, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1135, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 994, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1052, in compute_loss\n      return self.compiled_loss(\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 272, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"C:\\Users\\Shreyas\\anaconda3\\lib\\site-packages\\keras\\losses.py\", line 1879, in huber\n      error = tf.subtract(y_pred, y_true)\nNode: 'huber/Sub'\nOOM when allocating tensor with shape[1024,208,19875] and type float on /job:localhost/replica:0/task:0/device:CPU:0 by allocator cpu\n\t [[{{node huber/Sub}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_30571]"
     ]
    }
   ],
   "source": [
    "def bd_model(input_shape, output_sequence_length, english_vocab_size, other_vocab_size):\n",
    "   \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(GRU(128, return_sequences = True, dropout = 0.1), \n",
    "                           input_shape = input_shape[1:]))\n",
    "    model.add(TimeDistributed(Dense(other_vocab_size, activation = 'softmax')))\n",
    "    model.compile(loss = huber_loss, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "tmp_x = pad(preproc_english_sentences, preproc_other_sentences.shape[1])\n",
    "tmp_x = tmp_x.reshape((-1, preproc_other_sentences.shape[-2], 1))\n",
    "\n",
    "bidi_model = bd_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_other_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(other_tokenizer.word_index)+1)\n",
    "bidi_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n",
    "# Print prediction(s)\n",
    "print(logits_to_text(bidi_model.predict(tmp_x[:1])[0], other_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1cc051",
   "metadata": {
    "id": "2d1cc051"
   },
   "outputs": [],
   "source": [
    "def encdec_model(input_shape, output_sequence_length, english_vocab_size, other_vocab_size):\n",
    "  \n",
    "    learning_rate = 1e-3\n",
    "    model = Sequential()\n",
    "    model.add(GRU(128, input_shape = input_shape[1:], return_sequences = False))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(GRU(128, return_sequences = True))\n",
    "    model.add(TimeDistributed(Dense(other_vocab_size, activation = 'softmax')))\n",
    "    \n",
    "    model.compile(loss = huber_loss, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    return model\n",
    "tmp_x = pad(preproc_english_sentences)\n",
    "tmp_x = tmp_x.reshape((-1, preproc_english_sentences.shape[1], 1))\n",
    "tmp_x=np.delete(tmp_x,1,0)\n",
    "\n",
    "encodeco_model = encdec_model(\n",
    "    tmp_x.shape,\n",
    "    preproc_other_sentences.shape[1],\n",
    "    len(english_tokenizer.word_index)+1,\n",
    "    len(other_tokenizer.word_index)+1)\n",
    "encodeco_model.fit(tmp_x, preproc_other_sentences, batch_size=1024, epochs=20, validation_split=0.2)\n",
    "print(logits_to_text(encodeco_model.predict(tmp_x[:1])[0], other_tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d257dbd4",
   "metadata": {
    "id": "d257dbd4",
    "outputId": "53f81117-d58e-4d91-b64f-68d485e01781"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Loaded\n"
     ]
    }
   ],
   "source": [
    "def model_final(input_shape, output_sequence_length, english_vocab_size, other_vocab_size):\n",
    "  \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=english_vocab_size,output_dim=128,input_length=input_shape[1]))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=False)))\n",
    "    model.add(RepeatVector(output_sequence_length))\n",
    "    model.add(Bidirectional(GRU(256,return_sequences=True)))\n",
    "    model.add(TimeDistributed(Dense(other_vocab_size,activation='softmax')))\n",
    "    learning_rate = 0.005\n",
    "    \n",
    "    model.compile(loss = sparse_categorical_crossentropy, \n",
    "                 optimizer = Adam(learning_rate), \n",
    "                 metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "print('Final Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "78bdf123",
   "metadata": {
    "id": "78bdf123"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36m<cell line: 24>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([y_id_to_word[np\u001b[38;5;241m.\u001b[39margmax(x)] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m predictions[\u001b[38;5;241m1\u001b[39m]]))\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([y_id_to_word[np\u001b[38;5;241m.\u001b[39mmax(x)] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m y[\u001b[38;5;241m0\u001b[39m]]))\n\u001b[1;32m---> 24\u001b[0m \u001b[43mfinal_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreproc_english_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreproc_other_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother_tokenizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [46]\u001b[0m, in \u001b[0;36mfinal_predictions\u001b[1;34m(x, y, x_tk, y_tk)\u001b[0m\n\u001b[0;32m      3\u001b[0m tmp_X \u001b[38;5;241m=\u001b[39m pad(preproc_english_sentences)\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m model_final(tmp_X\u001b[38;5;241m.\u001b[39mshape,\n\u001b[0;32m      5\u001b[0m                     preproc_other_sentences\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],\n\u001b[0;32m      6\u001b[0m                     \u001b[38;5;28mlen\u001b[39m(english_tokenizer\u001b[38;5;241m.\u001b[39mword_index)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m      7\u001b[0m                     \u001b[38;5;28mlen\u001b[39m(other_tokenizer\u001b[38;5;241m.\u001b[39mword_index)\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreproc_other_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1024\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m17\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m y_id_to_word \u001b[38;5;241m=\u001b[39m {value: key \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m y_tk\u001b[38;5;241m.\u001b[39mword_index\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m     12\u001b[0m y_id_to_word[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<PAD>\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1557\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1558\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1561\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1562\u001b[0m ):\n\u001b[0;32m   1563\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1564\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1565\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1566\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:980\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    976\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall through to cond-based initialization.\u001b[39;00m\n\u001b[0;32m    977\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    978\u001b[0m     \u001b[38;5;66;03m# Lifting succeeded, so variables are initialized and we can run the\u001b[39;00m\n\u001b[0;32m    979\u001b[0m     \u001b[38;5;66;03m# stateless function.\u001b[39;00m\n\u001b[1;32m--> 980\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    981\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    982\u001b[0m   _, _, filtered_flat_args \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    983\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn\u001b[38;5;241m.\u001b[39m_function_spec\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    984\u001b[0m           \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2493\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2494\u001b[0m   (graph_function,\n\u001b[0;32m   2495\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2496\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2497\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1858\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1859\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1860\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1861\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1862\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1864\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1865\u001b[0m     args,\n\u001b[0;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1867\u001b[0m     executing_eagerly)\n\u001b[0;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def final_predictions(x, y, x_tk, y_tk):\n",
    "    global predictions\n",
    "    tmp_X = pad(preproc_english_sentences)\n",
    "    model = model_final(tmp_X.shape,\n",
    "                        preproc_other_sentences.shape[1],\n",
    "                        len(english_tokenizer.word_index)+1,\n",
    "                        len(other_tokenizer.word_index)+1)\n",
    "    \n",
    "    model.fit(tmp_X, preproc_other_sentences, batch_size = 1024, epochs = 17, validation_split = 0.2)\n",
    " \n",
    "    y_id_to_word = {value: key for key, value in y_tk.word_index.items()}\n",
    "    y_id_to_word[0] = '<PAD>'\n",
    "    sentence = 'brand bihar representative portal of bihar'\n",
    "    sentence = [x_tk.word_index[word] for word in sentence.split()]\n",
    "    sentence = pad_sequences([sentence], maxlen=x.shape[-1], padding='post')\n",
    "    sentences = np.array([sentence[0], x[0]])\n",
    "    predictions = model.predict(sentences, len(sentences))\n",
    "    print('Sample 1:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[0]]))\n",
    "    print('रोला रामायण')\n",
    "    print('Sample 2:')\n",
    "    print(' '.join([y_id_to_word[np.argmax(x)] for x in predictions[1]]))\n",
    "    print(' '.join([y_id_to_word[np.max(x)] for x in y[0]]))\n",
    "final_predictions(preproc_english_sentences, preproc_other_sentences, english_tokenizer, other_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97927a48",
   "metadata": {
    "id": "97927a48"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a67bc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
